{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "qmHP89_CmySZ"
      },
      "source": [
        "# Use Ragas to evaluate the OpenAI Assistant\n",
        "\n",
        "**Please note that this test requires a large amount of OpenAI api token consumption. Please read it carefully and Pay attention to the number of times you request access.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "P9PR2Ds8mySa"
      },
      "source": [
        "## 1. Prepare environment and data\n",
        "\n",
        "Before starting, you must set OPENAI_API_KEY in your environment variables."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "xqCOjZKkmySa"
      },
      "source": [
        "Install pip dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EG4-eN_imySa",
        "outputId": "3ae6ccc9-d6ae-48d3-8497-02192481e6d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.13.3-py3-none-any.whl (227 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/227.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.2/227.4 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.4/227.4 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting beir\n",
            "  Downloading beir-2.0.0.tar.gz (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Collecting ragas==0.0.17\n",
            "  Downloading ragas-0.0.17-py3-none-any.whl (39 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from ragas==0.0.17) (1.25.2)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from ragas==0.0.17) (4.38.1)\n",
            "Collecting sentence-transformers (from ragas==0.0.17)\n",
            "  Downloading sentence_transformers-2.5.1-py3-none-any.whl (156 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.5/156.5 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets (from ragas==0.0.17)\n",
            "  Downloading datasets-2.18.0-py3-none-any.whl (510 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.5/510.5 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tiktoken (from ragas==0.0.17)\n",
            "  Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain>=0.0.288 (from ragas==0.0.17)\n",
            "  Downloading langchain-0.1.11-py3-none-any.whl (807 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m807.5/807.5 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydantic<2.0 (from ragas==0.0.17)\n",
            "  Downloading pydantic-1.10.14-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pysbd>=0.3.4 (from ragas==0.0.17)\n",
            "  Downloading pysbd-0.3.4-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.1/71.1 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.10.0)\n",
            "Collecting pytrec_eval (from beir)\n",
            "  Downloading pytrec_eval-0.5.tar.gz (15 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting faiss_cpu (from beir)\n",
            "  Downloading faiss_cpu-1.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.0/27.0 MB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting elasticsearch==7.9.1 (from beir)\n",
            "  Downloading elasticsearch-7.9.1-py2.py3-none-any.whl (219 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m219.2/219.2 kB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from elasticsearch==7.9.1->beir) (2.0.7)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from elasticsearch==7.9.1->beir) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.4-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.8/77.8 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.288->ragas==0.0.17) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.288->ragas==0.0.17) (2.0.27)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.288->ragas==0.0.17) (3.9.3)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.288->ragas==0.0.17) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain>=0.0.288->ragas==0.0.17)\n",
            "  Downloading dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain>=0.0.288->ragas==0.0.17)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langchain-community<0.1,>=0.0.25 (from langchain>=0.0.288->ragas==0.0.17)\n",
            "  Downloading langchain_community-0.0.25-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m32.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-core<0.2,>=0.1.29 (from langchain>=0.0.288->ragas==0.0.17)\n",
            "  Downloading langchain_core-0.1.29-py3-none-any.whl (252 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m252.6/252.6 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-text-splitters<0.1,>=0.0.1 (from langchain>=0.0.288->ragas==0.0.17)\n",
            "  Downloading langchain_text_splitters-0.0.1-py3-none-any.whl (21 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain>=0.0.288->ragas==0.0.17)\n",
            "  Downloading langsmith-0.1.21-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.288->ragas==0.0.17) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain>=0.0.288->ragas==0.0.17) (8.2.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets->ragas==0.0.17) (3.13.1)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->ragas==0.0.17) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets->ragas==0.0.17) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets->ragas==0.0.17)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->ragas==0.0.17) (3.4.1)\n",
            "Collecting multiprocess (from datasets->ragas==0.0.17)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.2.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets->ragas==0.0.17) (2023.6.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets->ragas==0.0.17) (0.20.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets->ragas==0.0.17) (23.2)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers->ragas==0.0.17) (2.1.0+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers->ragas==0.0.17) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers->ragas==0.0.17) (1.11.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers->ragas==0.0.17) (9.4.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->ragas==0.0.17) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers->ragas==0.0.17) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers->ragas==0.0.17) (0.4.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.288->ragas==0.0.17) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.288->ragas==0.0.17) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.288->ragas==0.0.17) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.288->ragas==0.0.17) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.288->ragas==0.0.17) (1.9.4)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain>=0.0.288->ragas==0.0.17)\n",
            "  Downloading marshmallow-3.21.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain>=0.0.288->ragas==0.0.17)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain>=0.0.288->ragas==0.0.17)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain>=0.0.288->ragas==0.0.17)\n",
            "  Downloading orjson-3.9.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.5/138.5 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain>=0.0.288->ragas==0.0.17) (3.3.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain>=0.0.288->ragas==0.0.17) (3.0.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers->ragas==0.0.17) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers->ragas==0.0.17) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers->ragas==0.0.17) (3.1.3)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers->ragas==0.0.17) (2.1.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers->ragas==0.0.17) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers->ragas==0.0.17) (3.3.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain>=0.0.288->ragas==0.0.17)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers->ragas==0.0.17) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence-transformers->ragas==0.0.17) (1.3.0)\n",
            "Building wheels for collected packages: beir, pytrec_eval\n",
            "  Building wheel for beir (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for beir: filename=beir-2.0.0-py3-none-any.whl size=63550 sha256=883f09c3cae68a14b54b3d5dcf6d06bb4b88dfb95b02c15fa1bf9435b4481bca\n",
            "  Stored in directory: /root/.cache/pip/wheels/1c/14/96/c606ede3c10e9300ef771a6183af09d389459195ff5f854862\n",
            "  Building wheel for pytrec_eval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytrec_eval: filename=pytrec_eval-0.5-cp310-cp310-linux_x86_64.whl size=308205 sha256=490e370c84167cb51814bf84a00f557e9838fc6d25da7f91c4a1856327dc2d15\n",
            "  Stored in directory: /root/.cache/pip/wheels/51/3a/cd/dcc1ddfc763987d5cb237165d8ac249aa98a23ab90f67317a8\n",
            "Successfully built beir pytrec_eval\n",
            "Installing collected packages: pytrec_eval, pysbd, pydantic, orjson, mypy-extensions, marshmallow, jsonpointer, h11, faiss_cpu, elasticsearch, dill, typing-inspect, tiktoken, multiprocess, langsmith, jsonpatch, httpcore, langchain-core, httpx, dataclasses-json, openai, langchain-text-splitters, langchain-community, datasets, sentence-transformers, langchain, ragas, beir\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.6.3\n",
            "    Uninstalling pydantic-2.6.3:\n",
            "      Successfully uninstalled pydantic-2.6.3\n",
            "Successfully installed beir-2.0.0 dataclasses-json-0.6.4 datasets-2.18.0 dill-0.3.8 elasticsearch-7.9.1 faiss_cpu-1.8.0 h11-0.14.0 httpcore-1.0.4 httpx-0.27.0 jsonpatch-1.33 jsonpointer-2.4 langchain-0.1.11 langchain-community-0.0.25 langchain-core-0.1.29 langchain-text-splitters-0.0.1 langsmith-0.1.21 marshmallow-3.21.1 multiprocess-0.70.16 mypy-extensions-1.0.0 openai-1.13.3 orjson-3.9.15 pydantic-1.10.14 pysbd-0.3.4 pytrec_eval-0.5 ragas-0.0.17 sentence-transformers-2.5.1 tiktoken-0.6.0 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "! python -m pip install openai beir pandas ragas==0.0.17"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "IG2kb2xVmySb"
      },
      "source": [
        "Download [Financial Opinion Mining and Question Answering (fiqa) Dataset](https://sites.google.com/view/fiqa/) data if it not exists in your local space. We convert it into a ragas form that is easier to process, referring from this [script](https://github.com/explodinggradients/ragas/blob/main/experiments/baselines/fiqa/dataset-exploration-and-baseline.ipynb)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "ad4a1dab482a46ff80e90d996d1052bf",
            "ec27cee4940d4d17ae3f6a4519d69641",
            "419c0751bdae42b8a538311c640bf278",
            "4467dc249d30465bba94d2b64c1bf086",
            "044a92adc2104c278835d8517dcabbb2",
            "851b3b0561564960a3976e510bba8df7",
            "e74cedccaa8c4642ab1c54f75739f0d3",
            "de8e8cd4ea1e449396f06d142a64767f",
            "a8360aa62ca34f7f834510c62ce904f3",
            "5bfadee2c9104f6e9b488a6bf9d33b1d",
            "3a51e63fa223461fa865c0b2296bf6cf"
          ]
        },
        "id": "bMhNVtfRmySb",
        "outputId": "d3c4ffeb-8d6d-4d04-c1ca-21e2acf79d40"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ad4a1dab482a46ff80e90d996d1052bf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "./knowledge_datas/fiqa.zip:   0%|          | 0.00/17.1M [00:00<?, ?iB/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1706\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from datasets import Dataset\n",
        "from beir import util\n",
        "import os\n",
        "\n",
        "def prepare_fiqa_without_answer(knowledge_path):\n",
        "    dataset_name = \"fiqa\"\n",
        "\n",
        "    if not os.path.exists(os.path.join(knowledge_path, f'{dataset_name}.zip')):\n",
        "        url = (\n",
        "            \"https://public.ukp.informatik.tu-darmstadt.de/thakur/BEIR/datasets/{}.zip\".format(\n",
        "                dataset_name\n",
        "            )\n",
        "        )\n",
        "        util.download_and_unzip(url, knowledge_path)\n",
        "\n",
        "    data_path = os.path.join(knowledge_path, 'fiqa')\n",
        "    with open(os.path.join(data_path, \"corpus.jsonl\")) as f:\n",
        "        cs = [pd.Series(json.loads(l)) for l in f.readlines()]\n",
        "\n",
        "    corpus_df = pd.DataFrame(cs)\n",
        "\n",
        "    corpus_df = corpus_df.rename(columns={\"_id\": \"corpus-id\", \"text\": \"ground_truth\"})\n",
        "    corpus_df = corpus_df.drop(columns=[\"title\", \"metadata\"])\n",
        "    corpus_df[\"corpus-id\"] = corpus_df[\"corpus-id\"].astype(int)\n",
        "    corpus_df.head()\n",
        "\n",
        "    with open(os.path.join(data_path, \"queries.jsonl\")) as f:\n",
        "        qs = [pd.Series(json.loads(l)) for l in f.readlines()]\n",
        "\n",
        "    queries_df = pd.DataFrame(qs)\n",
        "    queries_df = queries_df.rename(columns={\"_id\": \"query-id\", \"text\": \"question\"})\n",
        "    queries_df = queries_df.drop(columns=[\"metadata\"])\n",
        "    queries_df[\"query-id\"] = queries_df[\"query-id\"].astype(int)\n",
        "    queries_df.head()\n",
        "\n",
        "    splits = [\"dev\", \"test\", \"train\"]\n",
        "    split_df = {}\n",
        "    for s in splits:\n",
        "        split_df[s] = pd.read_csv(os.path.join(data_path, f\"qrels/{s}.tsv\"), sep=\"\\t\").drop(\n",
        "            columns=[\"score\"]\n",
        "        )\n",
        "\n",
        "    final_split_df = {}\n",
        "    for split in split_df:\n",
        "        df = queries_df.merge(split_df[split], on=\"query-id\")\n",
        "        df = df.merge(corpus_df, on=\"corpus-id\")\n",
        "        df = df.drop(columns=[\"corpus-id\"])\n",
        "        grouped = df.groupby(\"query-id\").apply(\n",
        "            lambda x: pd.Series(\n",
        "                {\n",
        "                    \"question\": x[\"question\"].sample().values[0],\n",
        "                    \"ground_truths\": x[\"ground_truth\"].tolist(),\n",
        "                }\n",
        "            )\n",
        "        )\n",
        "\n",
        "        grouped = grouped.reset_index()\n",
        "        grouped = grouped.drop(columns=\"query-id\")\n",
        "        final_split_df[split] = grouped\n",
        "\n",
        "    return final_split_df\n",
        "\n",
        "\n",
        "knowledge_datas_path = './knowledge_datas'\n",
        "fiqa_path = os.path.join(knowledge_datas_path, 'fiqa_doc.txt')\n",
        "\n",
        "if not os.path.exists(knowledge_datas_path):\n",
        "    os.mkdir(knowledge_datas_path)\n",
        "contexts_list = []\n",
        "answer_list = []\n",
        "\n",
        "final_split_df = prepare_fiqa_without_answer(knowledge_datas_path)\n",
        "\n",
        "docs = []\n",
        "\n",
        "split = 'test'\n",
        "for ds in final_split_df[split][\"ground_truths\"]:\n",
        "    docs.extend([d for d in ds])\n",
        "print(len(docs))\n",
        "\n",
        "docs_str = '\\n'.join(docs)\n",
        "with open(fiqa_path, 'w') as f:\n",
        "    f.write(docs_str)\n",
        "\n",
        "split = 'test'\n",
        "question_list = final_split_df[split][\"question\"].to_list()\n",
        "ground_truth_list = final_split_df[split][\"ground_truths\"].to_list()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "cJXBws-imySc"
      },
      "source": [
        "Now we have the question list and the ground truth list. And the knowledge documents are prepared in `fiqa_path`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "AxTClziUmySc"
      },
      "source": [
        "## 2. Building RAG using OpenAI assistant\n",
        "\n",
        "To get the context content from the annotations returned by Open AI."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZAySZZzvmySc"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "from openai import OpenAI\n",
        "from google.colab import userdata\n",
        "client = OpenAI()\n",
        "\n",
        "# Set OPENAI_API_KEY in your environment value\n",
        "\n",
        "\n",
        "\n",
        "class OpenAITimeoutException(Exception):\n",
        "    pass\n",
        "\n",
        "\n",
        "def get_content_from_retrieved_message(message):\n",
        "    # Extract the message content\n",
        "    message_content = message.content[0].text\n",
        "    annotations = message_content.annotations\n",
        "    contexts = []\n",
        "    for annotation in annotations:\n",
        "        message_content.value = message_content.value.replace(annotation.text, f'')\n",
        "        if (file_citation := getattr(annotation, 'file_citation', None)):\n",
        "            contexts.append(file_citation.quote)\n",
        "    if len(contexts) == 0:\n",
        "        contexts = ['empty context.']\n",
        "    return message_content.value, contexts\n",
        "\n",
        "\n",
        "def try_get_answer_contexts(assistant_id, question, timeout_seconds=120):\n",
        "    thread = client.beta.threads.create(\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": question,\n",
        "            }\n",
        "        ]\n",
        "    )\n",
        "    thread_id = thread.id\n",
        "    run = client.beta.threads.runs.create(\n",
        "        thread_id=thread_id,\n",
        "        assistant_id=assistant_id,\n",
        "    )\n",
        "    start_time = time.time()\n",
        "    while True:\n",
        "        elapsed_time = time.time() - start_time\n",
        "        if elapsed_time > timeout_seconds:\n",
        "            raise Exception(\"OpenAI retrieving answer Timeout！\")\n",
        "\n",
        "        run = client.beta.threads.runs.retrieve(\n",
        "            thread_id=thread_id,\n",
        "            run_id=run.id\n",
        "        )\n",
        "        if run.status == 'completed':\n",
        "            break\n",
        "    messages = client.beta.threads.messages.list(\n",
        "        thread_id=thread_id\n",
        "    )\n",
        "    assert len(messages.data) > 1\n",
        "    res, contexts = get_content_from_retrieved_message(messages.data[0])\n",
        "    response = client.beta.threads.delete(thread_id)\n",
        "    assert response.deleted is True\n",
        "    return contexts, res\n",
        "\n",
        "\n",
        "def get_answer_contexts_from_assistant(question, assistant_id, timeout_seconds=120, retry_num=6):\n",
        "    res = 'failed. please retry.'\n",
        "    contexts = ['failed. please retry.']\n",
        "    try:\n",
        "        for _ in range(retry_num):\n",
        "            try:\n",
        "                contexts, res = try_get_answer_contexts(assistant_id, question, timeout_seconds)\n",
        "                break\n",
        "            except OpenAITimeoutException as e:\n",
        "                print('OpenAI retrieving answer Timeout, retry...')\n",
        "                continue\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "    return res, contexts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "3ey974BGmySd"
      },
      "source": [
        "Build assistant and upload knowledge files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GAaagZFHmySd"
      },
      "outputs": [],
      "source": [
        "file = client.files.create(\n",
        "    file=open(fiqa_path, \"rb\"),\n",
        "    purpose='assistants'\n",
        ")\n",
        "\n",
        "# Add the file to the assistant\n",
        "assistant = client.beta.assistants.create(\n",
        "    instructions=\"You are a customer support chatbot. You must use your retrieval tool to retrieve relevant knowledge to best respond to customer queries.\",\n",
        "    model=\"gpt-4-1106-preview\",\n",
        "    tools=[{\"type\": \"retrieval\"}],\n",
        "    file_ids=[file.id]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "9goVSO7wmySd"
      },
      "source": [
        "## 3. Start Ragas Evaluation\n",
        "\n",
        "Note that a large amount of OpenAI api token is consumed. Every time you ask a question and every evaluation, you will ask the OpenAI service. Please pay attention to your token consumption. If you only want to run a small number of tests, you can modify the code to reduce the test size."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "aY4g4UxwmySd",
        "outputId": "1ad0b0ce-71c9-41ab-896f-b39e4f141c74"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 5/5 [02:22<00:00, 28.52s/it]\n"
          ]
        }
      ],
      "source": [
        "for question in tqdm(question_list[:5]):\n",
        "    answer, contexts = get_answer_contexts_from_assistant(question, assistant.id)\n",
        "    # print(f'answer = {answer}')\n",
        "    # print(f'contexts = {contexts}')\n",
        "    # print('=' * 80)\n",
        "    answer_list.append(answer)\n",
        "    contexts_list.append(contexts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "Sgg0luiEmySd"
      },
      "source": [
        "You can choose the indicators you care about to test.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "CUG2btVfmySd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "319a531f-ac68-4498-dbe8-3fe28f0a589e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluating with [answer_similarity]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:01<00:00,  1.98s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'answer_similarity': 0.8000}\n"
          ]
        }
      ],
      "source": [
        "from ragas import evaluate\n",
        "from ragas.metrics import answer_relevancy, faithfulness, context_recall, context_precision, answer_similarity\n",
        "\n",
        "ds = Dataset.from_dict({\"question\": question_list[:5],\n",
        "                        \"contexts\": contexts_list[:5],\n",
        "                        \"answer\": answer_list[:5],\n",
        "                        \"ground_truths\": ground_truth_list[:5]})\n",
        "\n",
        "result = evaluate(\n",
        "    ds,\n",
        "    metrics=[\n",
        "        # context_precision,\n",
        "        # context_recall,\n",
        "        # faithfulness,\n",
        "        # answer_relevancy,\n",
        "        answer_similarity,\n",
        "        # answer_correctness,\n",
        "    ],\n",
        "\n",
        ")\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  CustomGPT"
      ],
      "metadata": {
        "id": "C3iP5Z7Crntc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install customgpt_client"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ASkZirHitG5z",
        "outputId": "cbafeef9-5ab1-42e8-8596-0b706bea2d55"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting customgpt_client\n",
            "  Downloading customgpt_client-1.2.1-py3-none-any.whl (507 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m507.0/507.0 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=21.3.0 in /usr/local/lib/python3.10/dist-packages (from customgpt_client) (23.2.0)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from customgpt_client) (2.8.2)\n",
            "Requirement already satisfied: requests==2.31.0 in /usr/local/lib/python3.10/dist-packages (from customgpt_client) (2.31.0)\n",
            "Collecting sseclient-py==1.7.2 (from customgpt_client)\n",
            "  Downloading sseclient_py-1.7.2-py2.py3-none-any.whl (8.4 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->customgpt_client) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->customgpt_client) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->customgpt_client) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->customgpt_client) (2024.2.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.8.0->customgpt_client) (1.16.0)\n",
            "Installing collected packages: sseclient-py, customgpt_client\n",
            "Successfully installed customgpt_client-1.2.1 sseclient-py-1.7.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from customgpt_client import CustomGPT\n",
        "from customgpt_client.types import File\n",
        "import uuid\n",
        "CustomGPT.api_key = os.environ.get('CUSTOMGPT_API_KEY')\n",
        "\n",
        "def get_customgpt_rag_response(question, project):\n",
        "    prompt = question\n",
        "    conversation_id = uuid.uuid4()\n",
        "    max_retries = 3\n",
        "    run_count = 0\n",
        "\n",
        "    while run_count < max_retries:\n",
        "        try:\n",
        "            response = CustomGPT.Conversation.send(project_id=project.id, session_id=conversation_id, prompt=prompt)\n",
        "            if response.status_code == 200:\n",
        "                openai_response = response.parsed.data.openai_response\n",
        "            else:\n",
        "                raise Exception(f\"Failed in generating CustomGPT Response::{response.status_code}\")\n",
        "            return openai_response\n",
        "        except Exception as e:\n",
        "            run_count += 1\n",
        "            time.sleep(2)\n",
        "\n",
        "\n",
        "def setup_project():\n",
        "    file_ids = []\n",
        "    project = CustomGPT.Project.create(project_name=\"Rag Evaluation\")\n",
        "    if project.status_code == 201:\n",
        "        project_id = project.parsed.data.id\n",
        "        source = CustomGPT.Source.create(project_id=project_id, file=File(payload=open(fiqa_path, \"rb\"), file_name=f\"Fiqa\"))\n",
        "\n",
        "        is_chat_active = 0\n",
        "        # Check to make sure at least one page is indexed\n",
        "        while not is_chat_active:\n",
        "            response_project = CustomGPT.Project.get(project_id=project_id)\n",
        "            json_project = response_project.parsed\n",
        "            is_chat_active = json_project.data.is_chat_active\n",
        "            time.sleep(5)\n",
        "\n",
        "        return project.parsed.data\n",
        "    else:\n",
        "        raise Exception(\"CustomGPT Project Creation Failed\")\n",
        "    pass\n",
        "\n",
        "project = setup_project()\n"
      ],
      "metadata": {
        "id": "4WKCy5wRtPTG"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for question in tqdm(question_list):\n",
        "    answer = get_customgpt_rag_response(question, project)\n",
        "    # print(f'answer = {answer}')\n",
        "    # print(f'contexts = {contexts}')\n",
        "    # print('=' * 80)\n",
        "    answer_list.append(answer)\n",
        "print(project.id)\n",
        "print(answer_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EvpAQgqsteuQ",
        "outputId": "b6f307e8-63ca-4f91-de34-e42f8a32cf2e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [02:15<00:00, 27.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23162\n",
            "[\"To deposit a cheque issued to an associate of your business into your business account, you can follow one of the two methods described below:\\n\\n1. Endorsement by the Associate: Have the associate sign the back of the cheque. This is known as endorsing a third-party cheque, and it is a perfectly legal process. After endorsement, you can deposit the cheque into your business account. Note that there might be a longer hold period for the cheque to clear, especially if it's a large amount or if you don't have a well-established relationship with the bank. To reduce complications, you can have the associate go to the bank and endorse the cheque in front of a teller while providing identification, even if you are not present yourself.\\n\\n2. Deposit and Transfer by the Associate: Alternatively, the associate could deposit the cheque into their own account and then write a cheque to the business. This way, once the funds have cleared in the associate's account, they can easily transfer the money to your business account by writing a business cheque.\\n\\nDo keep in mind that banks may have different policies regarding the deposit of third-party checks, so it would be wise to contact your bank directly to confirm their specific requirements and process for such transactions.\", 'Yes, you can definitely send a money order from USPS as a business. You are free to fill in whatever you want in the \"From\" section of a money order, including your business name and address. However, you should be aware that the price you pay only includes the money order itself. If you wish to mail it, you must provide your own envelope and stamp. Since a money order won\\'t leave you with a bank record of the payment, it\\'s important to keep other records of the transaction, such as the stub of the money order. Additionally, you may want to ask the contractor to give you a receipt for the payment.', 'According to the document, the IRS indicated that it is not necessary to obtain a new EIN when conducting business under multiple names. The IRS mentioned that by filing the appropriate employer federal tax return (940/941), the filing requirements would have been updated. The person on the call with the IRS had the filing requirements for their LLC updated during the conversation, allowing them to use the same EIN moving forward.', \"To apply for and receive business credit, you should set up a meeting with the bank that manages your business checking account. It's recommended to go in person and bring relevant business financial statements, such as profit and loss statements, your balance sheet, and a record of your historical cash flow. The purpose of this meeting is to ensure that your banker understands your business and its financial needs, which can be crucial in establishing a relationship that may help facilitate the credit application process.\\n\\nYou should communicate your desire to establish credit and request a credit card account with a specific credit limit. Even if you have a credit history that might not meet the usual requirements, your banker might be able to assist in pushing your application through. Should you not receive the desired limit initially, it provides an opportunity for review and improvement, and you can revisit the discussion with your banker in 6 to 12 months.\\n\\nHaving an ongoing relationship with your banker can be beneficial when you want to explore other financial products, such as a line of credit or a business loan, in the future. Regularly meeting with your banker and providing updated financial statements helps both in maintaining the relationship and in analyzing and understanding the financial health of your business.\", \"The process of transferring a 401(k) after a business closure appears to depend on the structure of the corporation you had set up. If your business was set up as a sole proprietorship, then Solo 401(k) contributions, whether they were made by you as an employee or an employer, will be deducted from your gross income but will not reduce it. On the other hand, if the business was set up as an S-Corp, then the employer contributions will be deducted from wages and won't be reflected in Box 1 of your W-2, thus reducing your gross income. Employee contributions would still be reflected in Box 3 and 5 for FICA/payroll tax purposes. \\n\\nPlease note that this information pertains to the tax implications of 401(k) contributions rather than the process of transferring the 401(k) itself. If your question specifically relates to the mechanics of transferring a 401(k) after a business closure, could you please provide more context or specify your needs?\", \"To deposit a cheque issued to an associate into your business account, you can follow these steps, based on the context provided:\\n\\n1. **Third-Party Cheque Endorsement**: Have the associate who the cheque is made out to sign the back of the cheque. This process turns it into a third-party cheque, which can then be deposited into your business account. It's important to note that this is perfectly legal.\\n\\n2. **Bank Policies**: Be aware that the bank may have specific policies regarding third-party cheques, especially if it's a large amount or if you're not very well known at the bank. The cheque may be subject to a longer hold period before the funds are available in your account, and the funds will only be accessible if the cheque clears.\\n\\n3. **In-Person Endorsement**: If there are concerns due to the amount or bank policies, you can have the associate go to the bank and endorse the cheque in front of a teller, showing some form of ID. This step is not always necessary, but it can help if there are any issues with the deposit.\\n\\n4. **Alternative Deposit Method**: As an alternative, the associate could deposit the cheque into their own account and then write a cheque to the business. This method might be simpler but involves an extra step and might delay access to the funds.\\n\\n5. **Account Number Deposits**: Remember, anyone can deposit money into your account if they have the account number. However, for cheque deposits, especially third-party cheques, banks may require more direct involvement to prevent fraud and ensure compliance with their policies.\\n\\nBy following these steps, you should be able to successfully deposit a cheque issued to an associate into your business account. Always check with your bank first to understand their specific requirements and policies regarding third-party cheque deposits.\", 'Yes, you can send a money order from USPS as a business. You have the flexibility to fill in whatever you want in the \"From\" section of a money order, so including your business name and address would be perfectly fine. This allows businesses to use money orders for various transactions, ensuring a secure method of payment without directly involving bank accounts.', 'It\\'s possible for a single entity to operate under multiple business names. This is often achieved through the use of \"Doing Business As\" (DBA) names. Here\\'s how it relates to the context provided:\\n\\n1. **Creating a DBA**: In the scenario described, A Corp, which is the converted form of A LLC, creates a DBA where A Corp does business as B Shop. This allows A Corp to operate under both its original name and the DBA.\\n\\n2. **Bank Account Opening**: After creating the DBA, the next step involves going to the bank to open an account for A Corp DBA B Shop using the EIN created for A Corp. This is crucial because, as mentioned, banks require a state-issued DBA certificate and an Employer Identification Number (EIN) to open a business account.\\n\\n3. **EIN Usage**: The EIN is a unique identifier for the business entity with the IRS and is used for tax purposes. Even when doing business under a DBA, the original EIN for the entity (in this case, A Corp) is used. This is because the DBA is not a separate legal entity but rather a name under which the company operates.\\n\\n4. **Tax Reporting**: For tax purposes, the entity would report under its EIN, regardless of the number of DBAs it operates under. The IRS views the entity and its DBAs as a single entity for tax reporting.\\n\\n5. **Legal and Financial Separation**: It\\'s important to note that while a business can operate under multiple names, this does not create legal or financial separation between those names. All liability and financial responsibilities remain with the original entity (A Corp in this context).\\n\\nThis approach allows businesses to diversify their operations under different names while maintaining a single legal entity, simplifying tax and legal matters. However, it\\'s essential to comply with all local and federal regulations when registering and using DBAs.', \"Applying for and receiving business credit involves several steps and considerations to ensure you're not only approved but also that you're getting the most out of your credit options. Here's a detailed breakdown based on the context provided:\\n\\n### 1. **Understanding Your Credit Rating and Utilization**\\n   - **Credit Rating Agencies' Perspective**: They only look at the month-end totals on your credit card, as this is the information they receive from the issuing bank. High usage frequency doesn't directly affect your credit rating.\\n   - **Issuing Bank's Role**: Your credit limit and usage are closely monitored by the issuing bank. They reevaluate your credit limit typically after two to three months, and it could increase if you've maintained good standing.\\n\\n### 2. **Establishing a Relationship with Your Banker**\\n   - **Initial Meeting**: Set up a meeting with the bank that handles your business checking account. Bring your business statements, including profit and loss, balance sheet, and a spreadsheet showing your historical cash flow.\\n   - **Ongoing Relationship**: Continue to meet with your banker at least annually, updating them with your financial statements. This helps in analyzing your business and establishing a strong relationship for future credit needs.\\n\\n### 3. **Applying for a Business Credit Card**\\n   - **Requesting a Specific Credit Limit**: During your meeting with the banker, express your desire to establish credit and request a credit card account with a specific limit. Your banker might be able to assist in pushing your application through, even with limited credit history.\\n   - **Credit Increase Strategy**: If you're using your card frequently and maintaining good standing, the card company might offer a credit increase. If not, you can request an increase. If refused, you can consider switching to a different card or even threaten to cancel (though this may impact your credit score).\\n\\n### 4. **Managing Multiple Credit Cards**\\n   - **Credit Mix and Management**: It's advised not to open bank accounts just to obtain additional credit cards. Managing too many cards and incurring excessive debt can lead to financial strain. Ideally, live within your means and avoid carrying a balance on your credit cards.\\n\\n### 5. **Credit Scoring Changes**\\n   - **Recent Updates**: As of July 2017, having excessively large credit card limits can negatively affect your credit score. This is a shift from previous practices where large available credit was not directly penalized.\\n\\n### 6. **Reimbursement and Rewards**\\n   - **Business Expenses on Personal Cards**: If you're using personal credit cards for business expenses and getting reimbursed, it's essential to keep detailed receipts. While earning rewards or cashback on these purchases is generally accepted, it's crucial not to abuse this system.\\n\\nBy following these guidelines, you can navigate the process of applying for and managing business credit more effectively. Remember, maintaining a good credit standing and a strong relationship with your banker are key to securing and benefiting from business credit.\", \"When a business closes, handling a 401(k) can become a bit complex, but there are still clear steps you can take to manage your retirement savings effectively. Here's a detailed breakdown based on the context provided:\\n\\n1. **Understanding the Situation**: If your employer goes out of business, dealing with your 401(k) can become challenging. While 401(k) plans are generally fully funded, especially for former employers, accessing your funds might be delayed. This is because, in the event of a business closure, the plan might be locked for a period while bankruptcy proceedings are underway.\\n\\n2. **Immediate Steps**: \\n   - **Check the Status of Your 401(k)**: First, determine the current status of your 401(k) plan. Even if the company is closing, your 401(k) is held in trust and is separate from the company's assets. This means the funds should be secure, but you need to understand the specific situation with your plan.\\n   - **Contact the Plan Administrator**: The plan administrator, not necessarily your direct employer, is responsible for the management of the 401(k) plan. They should provide you with information on the status of the plan and your options.\\n\\n3. **Options for Your 401(k)**:\\n   - **Rollover to an IRA**: Rolling over your 401(k) to an Individual Retirement Account (IRA) is often a recommended step. This allows you to consolidate your retirement savings and potentially access a wider range of investment options with lower fees. The process involves opening an IRA (if you don't already have one) and requesting a direct rollover from your 401(k) plan.\\n   - **Rollover to a New Employer’s 401(k)**: If you have a new job that offers a 401(k) plan, you might be able to roll your old 401(k) into the new plan. This requires coordination between your new employer's HR department and the plan administrator of your old 401(k). Not all plans accept rollovers, so it's important to verify this option.\\n\\n4. **Considerations**:\\n   - **Protection from Creditors**: One advantage of keeping your retirement savings in a 401(k) is the legal protection from creditors. In case you are sued, 401(k) assets are generally better protected than IRA assets.\\n   - **Investment Choices and Fees**: Rolling over to an IRA might offer you more investment choices and lower fees compared to sticking with a 401(k) plan, especially if the plan was associated with a now-closed business.\\n\\n5. **Actionable Steps**:\\n   - **Gather Necessary Information**: Obtain any necessary paperwork from the plan administrator, including rollover forms and instructions on where and to whom the rollover check should be made payable.\\n   - **Open an IRA**: If you choose to roll over to an IRA and don't already have one, research providers to find one that suits your investment style and offers competitive fees.\\n   - **Initiate the Rollover**: Contact the plan administrator to initiate the rollover process. If rolling over to a new employer's 401(k), coordinate with your new employer's HR department.\\n\\n6. **Avoiding Cash-Outs**: It's generally advisable to avoid cashing out your 401(k), especially if you're under 59 ½, due to potential taxes and penalties.\\n\\nBy understanding your options and taking proactive steps, you can effectively manage your 401(k) after your employer goes out of business, ensuring your retirement savings continue to grow.\"]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ragas import evaluate\n",
        "from ragas.metrics import answer_relevancy, faithfulness, context_recall, context_precision, answer_similarity\n",
        "\n",
        "ds = Dataset.from_dict({\"question\": question_list,\n",
        "                        # \"contexts\": contexts_list,\n",
        "                        \"answer\": answer_list,\n",
        "                        \"ground_truths\": ground_truth_list})\n",
        "\n",
        "result = evaluate(\n",
        "    ds,\n",
        "    metrics=[\n",
        "        # context_precision,\n",
        "        # context_recall,\n",
        "        # faithfulness,\n",
        "        # answer_relevancy,\n",
        "        answer_similarity,\n",
        "        # answer_correctness,\n",
        "    ],\n",
        "\n",
        ")\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2dzwHhnRx7y7",
        "outputId": "3d0dc477-e437-4513-9b02-7d73820042f3"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluating with [answer_similarity]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:01<00:00,  1.69s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'answer_similarity': 0.8000}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Cz5XW1GKx8yD"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "044a92adc2104c278835d8517dcabbb2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a51e63fa223461fa865c0b2296bf6cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "419c0751bdae42b8a538311c640bf278": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de8e8cd4ea1e449396f06d142a64767f",
            "max": 17948027,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a8360aa62ca34f7f834510c62ce904f3",
            "value": 17948027
          }
        },
        "4467dc249d30465bba94d2b64c1bf086": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5bfadee2c9104f6e9b488a6bf9d33b1d",
            "placeholder": "​",
            "style": "IPY_MODEL_3a51e63fa223461fa865c0b2296bf6cf",
            "value": " 17.1M/17.1M [00:01&lt;00:00, 14.3MiB/s]"
          }
        },
        "5bfadee2c9104f6e9b488a6bf9d33b1d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "851b3b0561564960a3976e510bba8df7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8360aa62ca34f7f834510c62ce904f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ad4a1dab482a46ff80e90d996d1052bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ec27cee4940d4d17ae3f6a4519d69641",
              "IPY_MODEL_419c0751bdae42b8a538311c640bf278",
              "IPY_MODEL_4467dc249d30465bba94d2b64c1bf086"
            ],
            "layout": "IPY_MODEL_044a92adc2104c278835d8517dcabbb2"
          }
        },
        "de8e8cd4ea1e449396f06d142a64767f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e74cedccaa8c4642ab1c54f75739f0d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ec27cee4940d4d17ae3f6a4519d69641": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_851b3b0561564960a3976e510bba8df7",
            "placeholder": "​",
            "style": "IPY_MODEL_e74cedccaa8c4642ab1c54f75739f0d3",
            "value": "./knowledge_datas/fiqa.zip: 100%"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}